{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recongnition is an NLP task that sets it's goal to identify proper nouns i.e. names of indeviduals, locations and organizaitons.<br>\n",
    "In the task we are using the data set conll2002;<br> The data set is makred by both POS and NER tags;\n",
    "\n",
    "**copying word2vec file**<br>\n",
    "Before the run, download and copy word to vec file from:<br>\n",
    "* URL: https://github.com/uchile-nlp/spanish-word-embeddings\n",
    "* section: GloVe embeddings from SBWC\n",
    "* file link: \"Vector format (.vec.gz) (906 MB)\"\n",
    "\n",
    "to: ./notbookPath/data/glove-sbwc.i25.vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data\n",
    "First we check that indeed the data exist and see the format of it's records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esp.train:: data point: type <class 'method'>; value <bound method LazyMap.__getitem__ of [Tree('S', [Tree('LOC', [('Melbourne', 'NP')]), ('(', 'Fpa'), Tree('LOC', [('Australia', 'NP')]), (')', 'Fpt'), (',', 'Fc'), ('25', 'Z'), ('may', 'NC'), ('(', 'Fpa'), Tree('ORG', [('EFE', 'NC')]), (')', 'Fpt'), ('.', 'Fp')]), Tree('S', [('-', 'Fg')]), ...]>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import conll2002\n",
    "from nltk.chunk import tree2conlltags\n",
    "\n",
    "etr = conll2002.chunked_sents('esp.train')  # In Spanish\n",
    "eta = conll2002.chunked_sents('esp.testa')  # In Spanish\n",
    "etb = conll2002.chunked_sents('esp.testb')  # In Spanish\n",
    "\n",
    "dtr = conll2002.chunked_sents('ned.train')  # In Dutch\n",
    "dta = conll2002.chunked_sents('ned.testa')  # In Dutch\n",
    "dtb = conll2002.chunked_sents('ned.testb')  # In Dutch\n",
    "\n",
    "x = etr.__getitem__\n",
    "print(\"esp.train:: data point: type %s; value %s\" % (type(x), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recived sentence structure:**<br>\n",
    "We see that data point from the data set is a sentences, represented in a tree format - the chunked sentence format.\n",
    "Chunked sentence is a format in which the sentence tokens are grouped to by their function in the sentence; That may be usefull to check validity of the BIO tags and fix them, but initially we will not need that structure; <br>Therefore we will transform the sentence to a list of 3-tuples of <token, postag, biotag>; <br>\n",
    "\n",
    "**List sentence structure:**<br>\n",
    "$\\{<token, postag, biotag>_1...<token, postag, biotag>_k\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will note the difference between the types of the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree format:\n",
      "(S\n",
      "  (LOC Melbourne/NP)\n",
      "  (/Fpa\n",
      "  (LOC Australia/NP)\n",
      "  )/Fpt\n",
      "  ,/Fc\n",
      "  25/Z\n",
      "  may/NC\n",
      "  (/Fpa\n",
      "  (ORG EFE/NC)\n",
      "  )/Fpt\n",
      "  ./Fp)\n",
      "\n",
      "\n",
      "list-of-tuples format:\n",
      "[('Melbourne', 'NP', 'B-LOC'), ('(', 'Fpa', 'O'), ('Australia', 'NP', 'B-LOC'), (')', 'Fpt', 'O'), (',', 'Fc', 'O'), ('25', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFE', 'NC', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# printing a single word from a sentence\n",
    "\n",
    "sent = etr[0]\n",
    "sent_vec = tree2conlltags(sent)\n",
    "\n",
    "print(\"tree format:\\n%s\" % sent)\n",
    "print(\"\\n\")\n",
    "print(\"list-of-tuples format:\\n%s\" % sent_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing initial features for vector representation\n",
    "Before training, we need to generate a vector representation of a token in thw data; \n",
    "**feature selection** is a task that many times require prior knowlage on the task and it's efficient predictive features.\n",
    "\n",
    "For initial stage, we have selected the folowing features:\n",
    "* word form, in small letters\n",
    "* part of speach\n",
    "* prefixes {1,2}\n",
    "* suffixes {1,2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing a word\n",
    "Following code generates a vector from a word in a given sentence:<br>\n",
    "\n",
    "**Note: prepered infrasturucure to flexibly choose model order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool2int(bool):\n",
    "    if bool:           return 1\n",
    "    else:              return 0\n",
    "\n",
    "def setBoolVal(bool=None):\n",
    "    if (bool==None):   return 0.0\n",
    "    else:              return 2.0*(bool2int(bool)-0.5)\n",
    "\n",
    "def getAdjWordFeatures(token=None, postag=None):\n",
    "    # manually selected features for the adjacent word\n",
    "    if (token == None):\n",
    "        features = [\"\",\n",
    "                    postag,\n",
    "                    0,\n",
    "                    0]\n",
    "    else:\n",
    "        features = [token.lower(),\n",
    "                    postag,\n",
    "                    setBoolVal(token.isdigit()),\n",
    "                    setBoolVal(token.isupper())]\n",
    "    return features\n",
    "\n",
    "def getWordFeatures(token, postag):\n",
    "    # manually selected features for the word\n",
    "    features = [token.lower(),\n",
    "                postag,\n",
    "                setBoolVal(token.isdigit()),\n",
    "                setBoolVal(token.isupper()),\n",
    "                token[:1],\n",
    "                token[:2],\n",
    "                token[-1:],\n",
    "                token[-2:]]\n",
    "    return features\n",
    "\n",
    "def word2features(sent, i, order):\n",
    "    # sent      list of 3-tuples, each tuple is <token, POS, NER-tag>\n",
    "    # i         index for tuple for feature extraction\n",
    "    # order     number of context words on each side to be added to the features\n",
    "    token  = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    # set token features\n",
    "    features = []\n",
    "    features.extend(getWordFeatures(token,postag))\n",
    "\n",
    "    # adding features for order-previous and order successive tokens\n",
    "    for j in range(order):\n",
    "        # previous words\n",
    "        prv = (i - (j + 1))\n",
    "        nxt = (i + (j + 1))\n",
    "\n",
    "        if (prv >= 0):\n",
    "            # token exist\n",
    "            prvToken  = sent[prv][0]\n",
    "            prvPostag = sent[prv][1]\n",
    "            features.extend(getAdjWordFeatures(prvToken, prvPostag))\n",
    "        else:\n",
    "            # add pad\n",
    "            features.extend(getAdjWordFeatures(token=None,postag=\"BOS\"))\n",
    "        if (nxt<len(sent)):\n",
    "            # token exist\n",
    "            nxtToken  = sent[nxt][0]\n",
    "            nxtPostag = sent[nxt][1]\n",
    "            features.extend(getAdjWordFeatures(nxtToken, nxtPostag))\n",
    "        else:\n",
    "            # add pad\n",
    "            features.extend(getAdjWordFeatures(token=None,postag=\"EOS\"))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Feature extraction:\n",
    "We now sample 2 words from a sentence to print it's vector representation by the features we have selected;<br>\n",
    "\n",
    "**Note:**<br>\n",
    "We are adding adjacent words, by configurable distance fromt he current word; That may require special attention on the vectorization process since we would like to have equal number of features for all words; (Also for words that their word-neighbourhood is **out of sentence bound**)<br>\n",
    "Therefore a padding is required for these out-of-sentence-bound indexes. And we would need to set neutral feature values for features that are associated with these indexes;\n",
    "\n",
    "chosen neutral values:\n",
    "* boolean valued features were transformed to **{-1,0,+1}** where **-1=False, +1=True, 0=value of padded**\n",
    "* For padded tokens, we state **'BOS' for begining of sentence and 'EOS' for end of sentence**\n",
    "\n",
    "Following code demonstrate 2 word samples from locations out-of-sentence-bound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample a token: index in sentence: 0; type <class 'tuple'>; value ('Melbourne', 'NP', 'B-LOC')\n",
      "['melbourne', 'NP', -1.0, -1.0, 'M', 'Me', 'e', 'ne', '', 'BOS', 0, 0, '(', 'Fpa', -1.0, -1.0, '', 'BOS', 0, 0, 'australia', 'NP', -1.0, -1.0]\n",
      "sample a token: index in sentence: 10; type <class 'tuple'>; value ('.', 'Fp', 'O')\n",
      "['.', 'Fp', -1.0, -1.0, '.', '.', '.', '.', ')', 'Fpt', -1.0, -1.0, '', 'EOS', 0, 0, 'efe', 'NC', -1.0, 1.0, '', 'EOS', 0, 0]\n"
     ]
    }
   ],
   "source": [
    "order = 2\n",
    "\n",
    "tokenIndex = 0\n",
    "print(\"sample a token: index in sentence: %d; type %s; value %s\" % (tokenIndex, type(sent_vec[tokenIndex]), sent_vec[tokenIndex]))\n",
    "print(word2features(sent_vec,tokenIndex,order))\n",
    "\n",
    "tokenIndex = len(sent_vec)-1\n",
    "print(\"sample a token: index in sentence: %d; type %s; value %s\" % (tokenIndex, type(sent_vec[tokenIndex]), sent_vec[tokenIndex]))\n",
    "print(word2features(sent_vec,tokenIndex,order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding\n",
    "Now we encode the data acording to above vectorization scheme;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding data set\n",
    "def sent2features(sent, order):\n",
    "    return [word2features(sent, i, order) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]# reaching a data point\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "def getX(sentenceDataSet,order):\n",
    "    xOut = []\n",
    "    for sent in sentenceDataSet:\n",
    "        sent_vec = tree2conlltags(sent)\n",
    "        xOut.extend(sent2features(sent_vec,order))\n",
    "    return xOut\n",
    "\n",
    "def getY(sentenceDataSet):\n",
    "    yOut = []\n",
    "    for sent in sentenceDataSet:\n",
    "        sent_vec = tree2conlltags(sent)\n",
    "        yOut.extend(sent2labels(sent_vec))\n",
    "    return yOut\n",
    "\n",
    "def getTokens(sentenceDataSet):\n",
    "    tokenOut =[]\n",
    "    for sent in sentenceDataSet:\n",
    "        sent_vec = tree2conlltags(sent)\n",
    "        tokenOut.extend(sent2tokens(sent_vec))\n",
    "    return tokenOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code defines methods to generate token data points and it's BIO tagging for training upon reciving a database of sentences as in chuncked sentence format; <br>We will print first data point and it's tagging from preprocessed data base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> testing encoding\n",
      "\n",
      "token sample: Melbourne\n",
      "y sample:     B-LOC\n",
      "x sample:     ['melbourne', 'NP', -1.0, -1.0, 'M', 'Me', 'e', 'ne', '', 'BOS', 0, 0, '(', 'Fpa', -1.0, -1.0, '', 'BOS', 0, 0, 'australia', 'NP', -1.0, -1.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"-> testing encoding\\n\")\n",
    "x           = getX(etr, order)\n",
    "y           = getY(etr)\n",
    "tokenList   = getTokens(etr)\n",
    "\n",
    "print(\"token sample: %s\" % tokenList[0])\n",
    "print(\"y sample:     %s\" % y[0])\n",
    "print(\"x sample:     %s\" % x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Trainning\n",
    "On the first clause we were asked to explore the data and vectorize each word according to the described in the notebook: http://nbviewer.jupyter.org/github/tpeng/python-crfsuite/blob/master/examples/CoNLL%202002.ipynb;\n",
    "\n",
    "If we want to train using CoNLL package or SciKitLearn package, we need to generate similar vector but in dictionary representation;\n",
    "\n",
    "**Why dictionary?**<br>\n",
    "These packages are designed to get a very sparse vectors; In order to save in space, they work with dictionary representation of a sparce vector; if a feature has 0 value, it will not exist in the dictionary representation (there will be no key of that feature);<br>\n",
    "\n",
    "**Pro** Space;<br> We consider for example just the lower case form of the word, as we have roughly ~200,000 values for word forms, we would have a 1 hot of 200,000 features. Dictionary representation deals with that sparsity;<br>\n",
    "\n",
    "**Con** Time complexity;<br> Reaching the element is still O(1) but we will suffer consftant factor related to the implementation of the dictionary.\n",
    "it will inflict constant factor to the run time as reaching an element is the most basic operation, done at least O(n);<br>\n",
    "\n",
    "We show the code update for that purpose - vectorization to dictinary representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool2int(bool):\n",
    "    if bool:           return 1\n",
    "    else:              return 0\n",
    "\n",
    "def setBoolVal(bool=None):\n",
    "    if (bool==None):   return 0.5\n",
    "    else:              return 1.0*bool2int(bool)\n",
    "\n",
    "def getPadWordFeatures(token=None, postag=None, pref=\"\"):\n",
    "    features = {pref + 'token':         token,\n",
    "                pref + 'postag':        postag,\n",
    "                pref + 'isdigit':       setBoolVal(None),\n",
    "                pref + 'isupper':       setBoolVal(None)}\n",
    "    return features\n",
    "\n",
    "def getAdjWordFeatures(token=None, postag=None, pref=\"\"):\n",
    "    # manually selected features for the adjacent word\n",
    "    features = {pref+'token.lower': token.lower(),\n",
    "                pref+'postag':      postag,\n",
    "                pref+'isdigit':     setBoolVal(token.isdigit()),\n",
    "                pref+'isupper':     setBoolVal(token.isupper())}\n",
    "    return features\n",
    "\n",
    "def getWordFeatures(token, postag):\n",
    "    # manually selected features for the word\n",
    "    features = {'token.lower':  token.lower(),\n",
    "                'postag':       postag,\n",
    "                'isdigit':      setBoolVal(token.isdigit()),\n",
    "                'isupper':      setBoolVal(token.isupper()),\n",
    "                'perf1':        token[:1],\n",
    "                'pref2':        token[:2],\n",
    "                'suff1':        token[-1:],\n",
    "                'suff2':        token[-2:]}\n",
    "    return features\n",
    "\n",
    "def word2features(sent, i, order):\n",
    "    # sent      list of 3-tuples, each tuple is <token, POS, NER-tag>\n",
    "    # i         index for tuple for feature extraction\n",
    "    # order     number of context words on each side to be added to the features\n",
    "    token  = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    # set token features\n",
    "    features = {}\n",
    "    features.update(getWordFeatures(token,postag))\n",
    "\n",
    "    # adding features for order-previous and order successive tokens\n",
    "    for j in range(order):\n",
    "        # previous words\n",
    "        prv = (i - (j + 1))\n",
    "        nxt = (i + (j + 1))\n",
    "        prvStr = str(prv)\n",
    "        nxtStr = str(nxt)\n",
    "\n",
    "        if (prv >= 0):\n",
    "            # token exist\n",
    "            prvToken  = sent[prv][0]\n",
    "            prvPostag = sent[prv][1]\n",
    "            features.update(getAdjWordFeatures(prvToken, prvPostag,prvStr))\n",
    "        else:\n",
    "            # add pad\n",
    "            features.update(getPadWordFeatures(token=\"PAD\",postag=\"BOS\", pref=prvStr))\n",
    "        if (nxt<len(sent)):\n",
    "            # token exist\n",
    "            nxtToken  = sent[nxt][0]\n",
    "            nxtPostag = sent[nxt][1]\n",
    "            features.update(getAdjWordFeatures(nxtToken, nxtPostag, nxtStr))\n",
    "        else:\n",
    "            # add pad\n",
    "            features.update(getPadWordFeatures(token=\"PAD\",postag=\"EOS\", pref=nxtStr))\n",
    "\n",
    "    return features\n",
    "\n",
    "# encoding data set\n",
    "def sent2features(sent, order):\n",
    "    return [word2features(sent, i, order) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]# reaching a data point\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "def getX(sentenceDataSet,order):\n",
    "    xOut = []\n",
    "    for sent in sentenceDataSet:\n",
    "        sent_vec = tree2conlltags(sent)\n",
    "        xOut.extend(sent2features(sent_vec,order))\n",
    "    return xOut\n",
    "\n",
    "def getY(sentenceDataSet):\n",
    "    yOut = []\n",
    "    for sent in sentenceDataSet:\n",
    "        sent_vec = tree2conlltags(sent)\n",
    "        yOut.extend(sent2labels(sent_vec))\n",
    "    return yOut\n",
    "\n",
    "def getTokens(sentenceDataSet):\n",
    "    tokenOut =[]\n",
    "    for sent in sentenceDataSet:\n",
    "        sent_vec = tree2conlltags(sent)\n",
    "        tokenOut.extend(sent2tokens(sent_vec))\n",
    "    return tokenOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we test again the vectorized represenation of a token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> encoding training data\n",
      "\n",
      "data size:  |X_train| = 264715; type = <class 'list'>\n",
      "label size: |Y_train| = 264715; type = <class 'list'>\n",
      "\n",
      "\n",
      "-> testing encoding\n",
      "\n",
      "token sample: Melbourne\n",
      "y sample:     B-LOC\n",
      "x sample:     {'token.lower': 'melbourne', 'postag': 'NP', 'isdigit': 0.0, 'isupper': 0.0, 'perf1': 'M', 'pref2': 'Me', 'suff1': 'e', 'suff2': 'ne', '-1token': 'PAD', '-1postag': 'BOS', '-1isdigit': 0.5, '-1isupper': 0.5, '1token.lower': '(', '1postag': 'Fpa', '1isdigit': 0.0, '1isupper': 0.0, '-2token': 'PAD', '-2postag': 'BOS', '-2isdigit': 0.5, '-2isupper': 0.5, '2token.lower': 'australia', '2postag': 'NP', '2isdigit': 0.0, '2isupper': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"-> encoding training data\\n\")\n",
    "X_train     = getX(etr, order)\n",
    "Y_train     = getY(etr)\n",
    "tokenList   = getTokens(etr)\n",
    "print(\"data size:  |X_train| = %d; type = %s\" % (len(X_train), type(X_train)))\n",
    "print(\"label size: |Y_train| = %d; type = %s\" % (len(Y_train), type(X_train)))\n",
    "\n",
    "print(\"\\n\\n-> testing encoding\\n\")\n",
    "print(\"token sample: %s\" % tokenList[0])\n",
    "print(\"y sample:     %s\" % Y_train[0])\n",
    "print(\"x sample:     %s\" % X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer\n",
    "For trainer we use the crfsuite package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> setting pycrfsuite trainer\n",
      "-> setting trainer parameters\n",
      "-> setting data to trainer\n"
     ]
    }
   ],
   "source": [
    "import pycrfsuite\n",
    "\n",
    "print(\"-> setting pycrfsuite trainer\")\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "print(\"-> setting trainer parameters\")\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "print(\"-> setting data to trainer\")\n",
    "trainer.append(X_train,Y_train)\n",
    "trainer.train('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier was trained and saved as an output file in:<br>\n",
    "**.../conll2002-esp.crfsuite**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a single sentence\n",
    "\n",
    "Before moving on towards mesuring the trained model, we would like to have a sanity check:<br> - taging and comparing a single sentence;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first encode the testa sentence data set to our format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> encoding test data with order 2\n"
     ]
    }
   ],
   "source": [
    "print(\"-> encoding test data with order %d\" % order)\n",
    "X_test      = getX(eta, order)\n",
    "Y_test      = getY(eta)\n",
    "token_test  = getTokens(eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now print 2 sample sentences and look at their predicted tags vs the true tag;<br>\n",
    "(**Recall our current model order is 2**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> setting tagger\n",
      "\n",
      "Sao Paulo ( Brasil ) , 23 may ( EFECOM ) .\n",
      "\n",
      "Predicted: B-LOC I-LOC O B-LOC O O O O O B-ORG O O\n",
      "Real     : B-LOC I-LOC O B-LOC O O O O O B-ORG O O\n",
      "\n",
      "La multinacional española Telefónica ha impuesto un récord mundial al poner en servicio tres millones de nuevas líneas en el estado brasileño de Sao Paulo desde que asumió el control de la operadora Telesp hace 20 meses , anunció hoy el presidente de Telefónica do Brasil , Fernando Xavier Ferreira .\n",
      "\n",
      "Predicted: O O O B-ORG O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O B-ORG O O O O O O O O O B-ORG I-ORG I-ORG O B-PER I-PER I-PER O\n",
      "Real     : O O O B-ORG O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O B-ORG O O O O O O O O O B-ORG I-ORG I-ORG O B-PER I-PER I-PER O\n"
     ]
    }
   ],
   "source": [
    "print(\"-> setting tagger\")\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002-esp.crfsuite')\n",
    "\n",
    "def getSentX(sent, order):\n",
    "    xOut = []\n",
    "    sent_vec = tree2conlltags(sent)\n",
    "    xOut.extend(sent2features(sent_vec, order))\n",
    "    return xOut\n",
    "\n",
    "def getSentY(sent):\n",
    "    yOut = []\n",
    "    sent_vec = tree2conlltags(sent)\n",
    "    yOut.extend(sent2labels(sent_vec))\n",
    "    return yOut\n",
    "\n",
    "def getSentTokens(sent):\n",
    "    tokenOut = []\n",
    "    sent_vec = tree2conlltags(sent)\n",
    "    tokenOut.extend(sent2tokens(sent_vec))\n",
    "    return tokenOut\n",
    "\n",
    "example_sent = eta[0]\n",
    "print(\"\")\n",
    "print(' '.join(getSentTokens(example_sent)), end='\\n\\n')\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(getSentX(example_sent, order))))\n",
    "print(\"Real     :\", ' '.join(getSentY(example_sent)))\n",
    "\n",
    "example_sent = eta[2]\n",
    "print(\"\")\n",
    "print(' '.join(getSentTokens(example_sent)), end='\\n\\n')\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(getSentX(example_sent, order))))\n",
    "print(\"Real     :\", ' '.join(getSentY(example_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagging seem ok, meanning that we don't have compatability issues and we may proceed to the main task - measuring the effect of model order on it's pereformance;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiencing the effect of model order on results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now will run 6 experiments, each mesuring performance for trained model;\n",
    "\n",
    "experimens:\n",
    "* Spanish X model-order=0\n",
    "* Spanish X model-order=1\n",
    "* Spanish X model-order=2\n",
    "* Dutch X model-order=0\n",
    "* Dutch X model-order=1\n",
    "* Dutch X model-order=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model performance classification results for experiment: Lang=Spanish_X_Order=0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.61      0.76      0.68       985\n",
      "      I-LOC       0.61      0.70      0.66       336\n",
      "     B-MISC       0.58      0.48      0.52       445\n",
      "     I-MISC       0.39      0.50      0.44       654\n",
      "      B-ORG       0.81      0.68      0.74      1700\n",
      "      I-ORG       0.76      0.65      0.70      1366\n",
      "      B-PER       0.79      0.72      0.76      1222\n",
      "      I-PER       0.77      0.90      0.83       859\n",
      "\n",
      "avg / total       0.71      0.69      0.70      7567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def bio_classification_report(y_true, y_pred, ommitBaseClass):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(y_true)\n",
    "    y_pred_combined = lb.fit_transform(y_pred)\n",
    "    \n",
    "    if (ommitBaseClass):  tagset = set(lb.classes_) - {'O'}\n",
    "    else:                 tagset = set(lb.classes_)\n",
    "        \n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "\n",
    "def measureModel(train, test, order, experimentName = \"defExperimentName\", verbose = False, ommitBaseClass = True):\n",
    "    # encode training data\n",
    "    if verbose: print(\"-> encoding train data\")\n",
    "    X_train     = getX(train, order)\n",
    "    Y_train     = getY(train)\n",
    "    \n",
    "    # train a classifier\n",
    "    if verbose: print(\"-> setting trainer parameters\")\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "    trainer.set_params({\n",
    "        'c1': 1.0,   # coefficient for L1 penalty\n",
    "        'c2': 1e-3,  # coefficient for L2 penalty\n",
    "        'max_iterations': 50,  # stop earlier\n",
    "        # include transitions that are possible, but not observed\n",
    "        'feature.possible_transitions': True\n",
    "        })\n",
    "    if verbose: print(\"-> setting data to trainer\")\n",
    "    trainer.append(X_train,Y_train)\n",
    "    if verbose: print(\"-> training; classifier saved on ./%s\" % experimentName)\n",
    "    trainer.train(experimentName)\n",
    "    \n",
    "    # encode test data\n",
    "    if verbose: print(\"-> encoding test data\")\n",
    "    X_test      = getX(test, order)\n",
    "    Y_test      = getY(test)\n",
    "    \n",
    "    # tag test data (prediction)\n",
    "    if verbose: print(\"-> tagging test data with trained classifier %s\" % experimentName)\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open(experimentName)\n",
    "    Y_pred      = tagger.tag(X_test)  \n",
    "    \n",
    "    # print peasured results:\n",
    "    print(\"\\n\\nModel performance classification results for experiment: %s\" % experimentName)\n",
    "    print(bio_classification_report(Y_test, Y_pred, ommitBaseClass))\n",
    "\n",
    "\n",
    "measureModel(etr, eta, 0, experimentName = \"Lang=Spanish_X_Order=0\", verbose = False, ommitBaseClass = True)\n",
    "\n",
    "# measure models order={0,1,2} for Spanish\n",
    "measureModel(etr, eta, 0, experimentName = \"Lang=Spanish_X_Order=0\", verbose = False)\n",
    "measureModel(etr, eta, 1, experimentName = \"Lang=Spanish_X_Order=1\", verbose = False)\n",
    "measureModel(etr, eta, 2, experimentName = \"Lang=Spanish_X_Order=2\", verbose = False)\n",
    "\n",
    "# measure models order={0,1,2} for Spanish Dutch\n",
    "measureModel(dtr, dta, 0, experimentName = \"Lang=Dutch_X_Order=0\", verbose = False)\n",
    "measureModel(dtr, dta, 1, experimentName = \"Lang=Dutch_X_Order=1\", verbose = False)\n",
    "measureModel(dtr, dta, 2, experimentName = \"Lang=Dutch_X_Order=2\", verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results anlysis\n",
    "**base class \"O\" not omitted**\n",
    "We also present a single test where the base class \"O\" not omitted;<br>\n",
    "Indeed, the interesting cases are the other classes, therefore we focus on them but it is also nice to see one test with the base class; clearly it is shifting the overall precision to a non interesting high score;\n",
    "\n",
    "**Order 0 => order 1**<br>\n",
    "On both languages, we see improvment in all BIO tags (except from in Dutch tag 'I-MISC')\n",
    "That is expected behaviour, assuming these extra features from neighbouring words should imply relation on the classification of the tag;\n",
    "\n",
    "**Order 1 => order 2**<br>\n",
    "On both languages, we see non improved results when moving from order 1 => order 2 (Spanish avg presicion remains 0.73, while Duch avg presicion slightly deteriorates from 0.72 to 0.71).\n",
    "One may think that it is surprizing, but we sohould remmember 2 factors:\n",
    "* It may be the case that the relation between distance 2 of the location is quite weak\n",
    "* We did not take significant amount of features from the classified word own index. \n",
    "Therefore, selecting features as described on a small training data may cause weakning the 'important' features to effect weakly then they would in a larger sample;<br>\n",
    "\n",
    "concluding the remark:\n",
    "If one select large anount of features, one should make sure they are correspond to the magnitude of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Checking for sequensial related tag errors\n",
    "\n",
    "In NER task, the output can be partially self verified with respect to it's sequential rules;\n",
    "Below a code that verifies the sequential rules between a pair of adjacent bio-tags;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBX_IY(tag1: str, tag2: str):\n",
    "    if (tag1 != \"O\" and tag2 != \"O\"):\n",
    "        delType1, bioType1 = tag1.split('-')\n",
    "        delType2, bioType2 = tag2.split('-')\n",
    "        if (delType1 == \"B\" and delType2 == \"I\" and bioType1 != bioType2):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def isIX_IY(tag1: str, tag2: str):\n",
    "    if (tag1 != \"O\" and tag2 != \"O\"):\n",
    "        delType1, bioType1 = tag1.split('-')\n",
    "        delType2, bioType2 = tag2.split('-')\n",
    "        if (delType1 == \"I\" and delType2 == \"I\" and bioType1 != bioType2):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def isO_IX(tag1: str, tag2: str):\n",
    "    if (tag1 == \"O\" and tag2 != \"O\"):\n",
    "        delType2, bioType2 = tag2.split('-')\n",
    "        if (delType2 == \"I\"):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def countErr(Y_pred, ErrFunc):\n",
    "    errCnt = 0\n",
    "    for i in range(len(Y_pred) - 1):\n",
    "        tag1 = Y_pred[i]\n",
    "        tag2 = Y_pred[i + 1]\n",
    "        if ErrFunc(tag1, tag2): errCnt += 1\n",
    "    return errCnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validating error count check code:\n",
    "We must verify that the code indeed find such ileagal sequences;<br> \n",
    "Therefore, the following code generates ileagal pairs for that purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'I-PER', 'I-ORG']\n",
      "BX_IY error count =   0\n",
      "IX_IY error count =   1\n",
      "O_IX  error count =   1\n"
     ]
    }
   ],
   "source": [
    "# {'I-PER', 'B-LOC', 'O', 'I-LOC', 'B-PER', 'I-ORG', 'B-MISC', 'I-MISC', 'B-ORG'}\n",
    "errorSeq = [\"O\", \"I-PER\", \"I-ORG\"]\n",
    "print(errorSeq)\n",
    "print(\"BX_IY error count = %3d\" % countErr(errorSeq, isBX_IY))\n",
    "print(\"IX_IY error count = %3d\" % countErr(errorSeq, isIX_IY))\n",
    "print(\"O_IX  error count = %3d\" % countErr(errorSeq, isO_IX ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-MISC', 'I-ORG']\n",
      "BX_IY error count =   1\n",
      "IX_IY error count =   0\n",
      "O_IX  error count =   0\n"
     ]
    }
   ],
   "source": [
    "# {'I-PER', 'B-LOC', 'O', 'I-LOC', 'B-PER', 'I-ORG', 'B-MISC', 'I-MISC', 'B-ORG'}\n",
    "errorSeq = [\"O\", \"B-MISC\", \"I-ORG\"]\n",
    "print(errorSeq)\n",
    "print(\"BX_IY error count = %3d\" % countErr(errorSeq, isBX_IY))\n",
    "print(\"IX_IY error count = %3d\" % countErr(errorSeq, isIX_IY))\n",
    "print(\"O_IX  error count = %3d\" % countErr(errorSeq, isO_IX ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-LOC', 'I-LOC', 'I-ORG', 'B-ORG', 'I-MISC', 'O', 'B-MISC', 'I-PER']\n",
      "BX_IY error count =   2\n",
      "IX_IY error count =   1\n",
      "O_IX  error count =   0\n"
     ]
    }
   ],
   "source": [
    "# {'I-PER', 'B-LOC', 'O', 'I-LOC', 'B-PER', 'I-ORG', 'B-MISC', 'I-MISC', 'B-ORG'}\n",
    "errorSeq = [\"O\", \"B-LOC\", \"I-LOC\", \"I-ORG\", \"B-ORG\", \"I-MISC\", \"O\" , \"B-MISC\", \"I-PER\"]\n",
    "print(errorSeq)\n",
    "print(\"BX_IY error count = %3d\" % countErr(errorSeq, isBX_IY))\n",
    "print(\"IX_IY error count = %3d\" % countErr(errorSeq, isIX_IY))\n",
    "print(\"O_IX  error count = %3d\" % countErr(errorSeq, isO_IX ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing sequential correctness for all tests\n",
    "We may want to check all out test data i.e. {Spanish, Duch} X {a,b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Taged bio-labels sequential corectness experiment: Lang=Spanish_X_TestSet=a_X_order=0\n",
      "BX_IY error count =   0\n",
      "IX_IY error count =   0\n",
      "O_IX  error count =   0\n",
      "\n",
      "\n",
      "Taged bio-labels sequential corectness experiment: Lang=Spanish_X_TestSet=a_X_order=1\n",
      "BX_IY error count =   0\n",
      "IX_IY error count =   0\n",
      "O_IX  error count =   0\n"
     ]
    }
   ],
   "source": [
    "def checkLabelSequenceCorrectness(train, test, order, experimentName = \"defExperimentName\", verbose = False):\n",
    "    # encode training data\n",
    "    if verbose: print(\"-> encoding train data\")\n",
    "    X_train     = getX(train, order)\n",
    "    Y_train     = getY(train)\n",
    "    \n",
    "    # train a classifier\n",
    "    if verbose: print(\"-> setting trainer parameters\")\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "    trainer.set_params({\n",
    "        'c1': 1.0,   # coefficient for L1 penalty\n",
    "        'c2': 1e-3,  # coefficient for L2 penalty\n",
    "        'max_iterations': 50,  # stop earlier\n",
    "        # include transitions that are possible, but not observed\n",
    "        'feature.possible_transitions': True\n",
    "        })\n",
    "    if verbose: print(\"-> setting data to trainer\")\n",
    "    trainer.append(X_train,Y_train)\n",
    "    if verbose: print(\"-> training; classifier saved on ./%s\" % experimentName)\n",
    "    trainer.train(experimentName)\n",
    "    \n",
    "    # encode test data\n",
    "    if verbose: print(\"-> encoding test data\")\n",
    "    X_test      = getX(test, order)\n",
    "    Y_test      = getY(test)\n",
    "    \n",
    "    # tag test data (prediction)\n",
    "    if verbose: print(\"-> tagging test data with trained classifier %s\" % experimentName)\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open(experimentName)\n",
    "    Y_pred      = tagger.tag(X_test)  \n",
    "    \n",
    "    # print peasured results:\n",
    "    print(\"\\n\\nTaged bio-labels sequential corectness experiment: %s\" % experimentName)\n",
    "    print(\"BX_IY error count = %3d\" % countErr(Y_pred, isBX_IY))\n",
    "    print(\"IX_IY error count = %3d\" % countErr(Y_pred, isIX_IY))\n",
    "    print(\"O_IX  error count = %3d\" % countErr(Y_pred, isO_IX ))\n",
    "\n",
    "# testing sequential correctness of bio-tags\n",
    "order = 0\n",
    "checkLabelSequenceCorrectness(etr, eta, order, experimentName = \"Lang=Spanish_X_TestSet=a_X_order=0\", verbose = False)\n",
    "checkLabelSequenceCorrectness(etr, etb, order, experimentName = \"Lang=Spanish_X_TestSet=b_X_order=0\", verbose = False)\n",
    "\n",
    "checkLabelSequenceCorrectness(dtr, dta, order, experimentName = \"Lang=Dutch_X_TestSet=a_X_order=0\", verbose = False)\n",
    "checkLabelSequenceCorrectness(dtr, dtb, order, experimentName = \"Lang=Dutch_X_TestSet=b_X_order=0\", verbose = False)\n",
    "\n",
    "order = 1\n",
    "checkLabelSequenceCorrectness(etr, eta, order, experimentName = \"Lang=Spanish_X_TestSet=a_X_order=1\", verbose = False)\n",
    "checkLabelSequenceCorrectness(etr, etb, order, experimentName = \"Lang=Spanish_X_TestSet=b_X_order=1\", verbose = False)\n",
    "\n",
    "checkLabelSequenceCorrectness(dtr, dta, order, experimentName = \"Lang=Dutch_X_TestSet=a_X_order=1\", verbose = False)\n",
    "checkLabelSequenceCorrectness(dtr, dtb, order, experimentName = \"Lang=Dutch_X_TestSet=b_X_order=1\", verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results anlysis\n",
    "Quite surprisingly, there were no pair of bio-tags that forms an ileagal sequence (even though error locating code was validated);\n",
    "We are happy to see that in the predicted sequence there are no ileagal pairs of bio-tags;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Adding a feature: dence vector representation features addition\n",
    "\n",
    "In this section we are adding as a feature the word ebmeding form of the word;<br>\n",
    "For that purpose, we will use a pretrained word embeder, that was trained on spanish corpus;<br> \n",
    "\n",
    "The embeder recives a word, and return it's dense vector form;<br>\n",
    "\n",
    "Since it is known that word with similar meaning in languages tend to have some similarity on their dense form, we expect that adding that feature will capture the essence of the entity we are seacking, i.e. that indeed entityies has some similaruty in the dence vectore space (e.g. with respect to inner product) <br>\n",
    "\n",
    "We will present the results after adding that feature, expecting for improved performance;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moshe\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> data was loaded\n"
     ]
    }
   ],
   "source": [
    "# Code from the project refference notbook:\n",
    "from gensim.models.keyedvectors import Doc2VecKeyedVectors as dvk\n",
    "import data\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "wordvectors_file_vec = 'data\\glove-sbwc.i25.vec'\n",
    "cantidad = 10000\n",
    "wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec, limit=cantidad)\n",
    "print(\"-> data was loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "las\n",
      "300\n",
      "notfound\n",
      "found\n"
     ]
    }
   ],
   "source": [
    "# Reaching the data\n",
    "\n",
    "sampleWord = list(wordvectors.vocab.keys())[10]\n",
    "print(sampleWord)\n",
    "sampleWord2Vec = wordvectors[sampleWord]\n",
    "#print(sampleWord2Vec)\n",
    "dimention = len(wordvectors[sampleWord])\n",
    "print(dimention)\n",
    "\n",
    "if (not (\"fewgfhjqwiowehjwerpghiwer\" in wordvectors.vocab.keys())) : print(\"notfound\")\n",
    "if sampleWord in wordvectors.vocab.keys() : print(\"found\")\n",
    "# setting defualt vector;\n",
    "defVector = np.zeros(dimention) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### updating vectorizer code\n",
    "Below is the code to be updated in order to add the dence vector form of the word as a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the update needed for the feture format:\n",
    "denceVectoreNofParam = 100\n",
    "\n",
    "def word2vec(tokenLower):\n",
    "    if tokenLower in wordvectors.vocab.keys():\n",
    "        # found word\n",
    "        denceVecForm = wordvectors[tokenLower]\n",
    "    else:\n",
    "        # not found word\n",
    "        denceVecForm = np.zeros(denceVectoreNofParam)\n",
    "    return denceVecForm\n",
    "\n",
    "def getPadWordFeatures(token=None, postag=None, pref=\"\"):\n",
    "    features = {pref + 'token':         token,\n",
    "                pref + 'postag':        postag,\n",
    "                pref + 'isdigit':       setBoolVal(None),\n",
    "                pref + 'isupper':       setBoolVal(None)}\n",
    "    \n",
    "    # add dense vector form as a feature\n",
    "    denceFeatureDict = {}\n",
    "    for i in  range(denceVectoreNofParam):\n",
    "         featureName = pref+\"dence\"+str(i)\n",
    "         denceFeatureDict[featureName] = 0.0\n",
    "    features.update(denceFeatureDict)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def getAdjWordFeatures(token=None, postag=None, pref=\"\"):\n",
    "    # manually selected features for the adjacent word\n",
    "    features = {pref+'token.lower': token.lower(),\n",
    "                pref+'postag':      postag,\n",
    "                pref+'isdigit':     setBoolVal(token.isdigit()),\n",
    "                pref+'isupper':     setBoolVal(token.isupper())}\n",
    "    \n",
    "    # computing features for dence form\n",
    "    denceVecForm = word2vec(token.lower())\n",
    "    \n",
    "    # add dense vector form as a feature\n",
    "    # dim          = len(denceVecForm)\n",
    "    denceFeatureDict = {}\n",
    "    for i in  range(denceVectoreNofParam):\n",
    "         val = denceVecForm[i]\n",
    "         featureName = pref+\"dence\"+str(i)\n",
    "         denceFeatureDict[featureName] = val\n",
    "    features.update(denceFeatureDict)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def getWordFeatures(token, postag):\n",
    "    # manually selected features for the word\n",
    "    \n",
    "    features = {'token.lower':  token.lower(),\n",
    "                'postag':       postag,\n",
    "                'isdigit':      setBoolVal(token.isdigit()),\n",
    "                'isupper':      setBoolVal(token.isupper()),\n",
    "                'perf1':        token[:1],\n",
    "                'pref2':        token[:2],\n",
    "                'suff1':        token[-1:],\n",
    "                'suff2':        token[-2:]}\n",
    "    \n",
    "    # computing features for dence form\n",
    "    denceVecForm = word2vec(token.lower())\n",
    "    \n",
    "    # add dense vector form as a feature\n",
    "    # dim          = len(denceVecForm)\n",
    "    denceFeatureDict = {}\n",
    "    for i in  range(denceVectoreNofParam):\n",
    "         val = denceVecForm[i]\n",
    "         featureName = \"dence\"+str(i)\n",
    "         denceFeatureDict[featureName] = val\n",
    "    features.update(denceFeatureDict)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> encoding train data\n",
      "-> setting trainer parameters\n",
      "-> setting data to trainer\n",
      "-> training; classifier saved on ./addedWrod2VecFeature_Lang=Spanish_X_Order=0\n",
      "-> encoding test data\n",
      "-> tagging test data with trained classifier addedWrod2VecFeature_Lang=Spanish_X_Order=0\n",
      "\n",
      "\n",
      "Model performance classification results for experiment: addedWrod2VecFeature_Lang=Spanish_X_Order=0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.63      0.78      0.70       985\n",
      "      I-LOC       0.62      0.77      0.68       336\n",
      "     B-MISC       0.65      0.50      0.56       445\n",
      "     I-MISC       0.47      0.51      0.49       654\n",
      "      B-ORG       0.83      0.71      0.76      1700\n",
      "      I-ORG       0.77      0.69      0.73      1366\n",
      "      B-PER       0.83      0.76      0.79      1222\n",
      "      I-PER       0.86      0.93      0.89       859\n",
      "\n",
      "avg / total       0.74      0.72      0.73      7567\n",
      "\n",
      "-> encoding train data\n",
      "-> setting trainer parameters\n",
      "-> setting data to trainer\n",
      "-> training; classifier saved on ./addedWrod2VecFeature_Lang=Spanish_X_Order=1\n",
      "-> encoding test data\n",
      "-> tagging test data with trained classifier addedWrod2VecFeature_Lang=Spanish_X_Order=1\n",
      "\n",
      "\n",
      "Model performance classification results for experiment: addedWrod2VecFeature_Lang=Spanish_X_Order=1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.64      0.80      0.71       985\n",
      "      I-LOC       0.56      0.70      0.62       336\n",
      "     B-MISC       0.60      0.49      0.54       445\n",
      "     I-MISC       0.50      0.52      0.51       654\n",
      "      B-ORG       0.82      0.72      0.76      1700\n",
      "      I-ORG       0.79      0.69      0.74      1366\n",
      "      B-PER       0.85      0.78      0.81      1222\n",
      "      I-PER       0.86      0.92      0.89       859\n",
      "\n",
      "avg / total       0.75      0.73      0.73      7567\n",
      "\n",
      "-> encoding train data\n"
     ]
    }
   ],
   "source": [
    "measureModel(etr, eta, 0, experimentName = \"addedWrod2VecFeature_Lang=Spanish_X_Order=0\", verbose = True)\n",
    "measureModel(etr, eta, 1, experimentName = \"addedWrod2VecFeature_Lang=Spanish_X_Order=1\", verbose = True)\n",
    "measureModel(etr, eta, 2, experimentName = \"addedWrod2VecFeature_Lang=Spanish_X_Order=2\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results anlysis\n",
    "\n",
    "It above experiments we added features that were learned in an external dence vector representation model;\n",
    "We assumed that those features will have some effect on the preformence as they are related to the word location on the language topology;\n",
    "\n",
    "We faced with a problem: space complexity of that task is very high; the num of dimention of the represeitation is 300;\n",
    "For comparison, initially we had 8 features for central work and 4 for neighbouring words;\n",
    "\n",
    "The local system that ran the process was overlded on RAM, therefore operated on disk, wich is very slow;\n",
    "\n",
    "Therefore we tool only first 100 dence vectore features;\n",
    "\n",
    "order 0 = avg presicion = 0.74 => improvment over the best previous result of 0.73 avg precision<br>\n",
    "order 1 = arg precision = 0.75<br>\n",
    "order 2 = arg precision = still running<br>\n",
    "\n",
    "To conclude:<br>\n",
    "**Adding dence vector features may help significantly to improve results, but it is costly in space resources;**<br>\n",
    "(we could also run with all 300 features but that would be 3 times more space for the currently overloaded system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
